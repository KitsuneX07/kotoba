# kotoba

[![Crates.io](https://img.shields.io/crates/v/kotoba.svg)](https://crates.io/crates/kotoba)
[![Documentation](https://docs.rs/kotoba/badge.svg)](https://docs.rs/kotoba)
[![Build Status](https://img.shields.io/github/actions/workflow/status/KitsuneX07/kotoba/ci.yml)](https://github.com/KitsuneX07/kotoba/actions)
[![License](https://img.shields.io/crates/l/kotoba.svg)](LICENSE)

**kotoba** æ˜¯ä¸€ä¸ªç”¨äº Rust çš„ç»Ÿä¸€å¤šå‚å•† LLM è°ƒç”¨æŠ½è±¡å±‚ã€‚å®ƒé€šè¿‡ä¸€è‡´çš„ç±»å‹ç³»ç»Ÿå’Œ trait æŠ½è±¡ï¼ŒæŠ¹å¹³äº† OpenAIã€Anthropicã€Google Gemini ç­‰ä¸åŒ Provider ä¹‹é—´çš„ API å·®å¼‚ï¼Œä¸ºæ„å»º LLM åº”ç”¨æä¾›ç±»å‹å®‰å…¨ã€å¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ã€‚

å®ƒæ—¨åœ¨è§£å†³æ¨¡å‹ç¢ç‰‡åŒ–é—®é¢˜ï¼Œæä¾›ç»Ÿä¸€çš„æ¶ˆæ¯å»ºæ¨¡ã€å®¢æˆ·ç«¯è·¯ç”±ã€é”™è¯¯å¤„ç†ä¸é…ç½®åŠ è½½æœºåˆ¶ã€‚

## æ ¸å¿ƒç‰¹æ€§

- **ç»Ÿä¸€ç±»å‹ç³»ç»Ÿ (Unified Type System)**
  æä¾›æ ‡å‡†åŒ–çš„ `ChatRequest`, `Message`, `ContentPart` åŠ `ChatResponse` ç»“æ„ã€‚å³ä¾¿æ˜¯å¤šæ¨¡æ€è¾“å…¥ã€å·¥å…·è°ƒç”¨ (Tool Use) æˆ–æ¨ç†é“¾ (Reasoning)ï¼Œä¹Ÿèƒ½åœ¨ç»Ÿä¸€çš„ç»“æ„ä¸­å¤„ç†ã€‚

- **Provider æŠ½è±¡ (Provider Agnostic)**
  åŸºäº `LLMProvider` trait æ„å»ºã€‚å†…ç½® OpenAI (Chat/Responses), Anthropic Messages, Google Gemini æ”¯æŒã€‚å¼€å‘è€…å¯è½»æ¾æ‰©å±•è‡ªå®šä¹‰çš„ Provider ç½‘å…³ã€‚

- **çµæ´»çš„ä¼ è¾“å±‚ (Pluggable Transport)**
  ç½‘ç»œå±‚ä¸é€»è¾‘å±‚è§£è€¦ã€‚é€šè¿‡ `HttpTransport` æŠ½è±¡ï¼Œä½ å¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ `Reqwest`ï¼Œåœ¨æµ‹è¯•ç¯å¢ƒæ³¨å…¥ Mockï¼Œæˆ–æ¤å…¥è‡ªå®šä¹‰çš„é‡è¯•ä¸è§‚æµ‹ä¸­é—´ä»¶ã€‚

- **æ™ºèƒ½è·¯ç”±ä¸è°ƒåº¦ (Client-Side Routing)**
  `LLMClient` æ”¯æŒå¤š Provider å¹¶å­˜ã€‚æ”¯æŒé€šè¿‡ `CapabilityDescriptor` åŠ¨æ€æ¢æµ‹èƒ½åŠ›ï¼ˆå¦‚æ˜¯å¦æ”¯æŒæµå¼è¾“å‡ºã€å·¥å…·è°ƒç”¨ï¼‰ï¼Œå®ç°ä¸šåŠ¡ä¾§çš„é™çº§ç­–ç•¥ä¸ AB å®éªŒã€‚

- **é›†ä¸­å¼é…ç½® (Declarative Configuration)**
  æ”¯æŒä»é…ç½®æ–‡ä»¶æ‰¹é‡æ„å»ºå®¢æˆ·ç«¯ã€‚è‡ªåŠ¨å¤„ç† API Key æ˜ å°„ï¼ˆBearer/x-api-keyï¼‰ã€Base URL è¦†å†™åŠå‚å•†ç‰¹æœ‰å‚æ•°æ³¨å…¥ã€‚

- **å®Œå¤‡çš„é”™è¯¯å¤„ç† (Robust Error Handling)**
  ç»†ç²’åº¦çš„ `LLMError` æšä¸¾ï¼Œç²¾ç¡®åŒºåˆ†ç½‘ç»œä¼ è¾“ã€é‰´æƒå¤±è´¥ã€é€Ÿç‡é™åˆ¶ (Rate Limit) ä¸æ¨¡å‹èƒ½åŠ›ç¼ºå¤±ç­‰åœºæ™¯ã€‚

## å®‰è£…

åœ¨ `Cargo.toml` ä¸­æ·»åŠ ä¾èµ–ï¼š

```toml
[dependencies]
kotoba = "0.1" # è¯·æ›¿æ¢ä¸ºæœ€æ–°ç‰ˆæœ¬
tokio = { version = "1", features = ["full"] }
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

ä¸‹é¢çš„ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åˆå§‹åŒ–ä¸€ä¸ª OpenAI Provider å¹¶å‘é€æµå¼å¯¹è¯è¯·æ±‚ã€‚

```rust
use std::sync::Arc;
use futures_util::StreamExt;
use kotoba::{LLMClient, LLMError};
use kotoba::http::reqwest::default_dyn_transport;
use kotoba::provider::openai_chat::OpenAiChatProvider;
use kotoba::types::{ChatRequest, Message, Role, ContentPart, TextContent};

#[tokio::main]
async fn main() -> Result<(), LLMError> {
    // 1. åˆå§‹åŒ– HTTP ä¼ è¾“å±‚ä¸ Provider
    let transport = default_dyn_transport()?;
    let provider = OpenAiChatProvider::new(transport.clone(), std::env::var("OPENAI_API_KEY")?)
        .with_default_model("gpt-4o-mini");

    // 2. æ„å»ºå®¢æˆ·ç«¯å¹¶æ³¨å†Œ Provider Handle
    let client = LLMClient::builder()
        .register_handle("openai", Arc::new(provider))?
        .build();

    // 3. æ„é€ é€šç”¨è¯·æ±‚
    let request = ChatRequest::new(vec![
        Message {
            role: Role::user(),
            content: vec![ContentPart::Text(TextContent::from("è¯·ç”¨ä¸€å¥è¯ä»‹ç» Rust è¯­è¨€"))],
            ..Default::default()
        }
    ]);

    // 4. æ‰§è¡Œæµå¼è¯·æ±‚
    let mut stream = client.stream_chat("openai", request).await?;
  
    println!("Response:");
    while let Some(chunk) = stream.next().await {
        if let Ok(c) = chunk {
            // å¤„ç†æµå¼å¢é‡äº‹ä»¶
             println!("Chunk: {:?}", c.events);
        }
    }

    Ok(())
}
```

## é€šè¿‡é…ç½®åŠ è½½ (Configuration)

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œé€šå¸¸éœ€è¦ä»åŠ¨æ€é…ç½®åŠ è½½å¤šä¸ª Providerã€‚`kotoba` æä¾›äº†å¼€ç®±å³ç”¨çš„é…ç½®æ˜ å°„èƒ½åŠ›ã€‚

```rust
use kotoba::config::{ModelConfig, ProviderKind, Credential, build_client_from_configs};
use kotoba::http::reqwest::default_dyn_transport;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // æ¨¡æ‹ŸåŠ è½½é…ç½®ï¼ˆé€šå¸¸æ¥è‡ª config æ–‡ä»¶æˆ–é…ç½®ä¸­å¿ƒï¼‰
    let configs = vec![ModelConfig {
        handle: "gemini".into(),
        provider: ProviderKind::GoogleGemini,
        credential: Credential::ApiKey { 
            header: None, // è‡ªåŠ¨é€‚é… x-goog-api-key
            key: std::env::var("GEMINI_API_KEY")? 
        },
        default_model: Some("gemini-2.0-flash".into()),
        base_url: None,
        extra: Default::default(),
    }];

    // ä¸€æ¬¡æ€§æ„å»ºåŒ…å«æ‰€æœ‰ Provider çš„å®¢æˆ·ç«¯
    let client = build_client_from_configs(&configs, default_dyn_transport()?)?;
  
    // æ£€æŸ¥èƒ½åŠ›å¹¶è°ƒç”¨
    if client.capabilities("gemini").supports_streaming {
        let _ = client.chat("gemini", ChatRequest::from_user_text("Hello Gemini")).await?;
    }

    Ok(())
}
```

## Provider èƒ½åŠ›çŸ©é˜µ

`kotoba` åœ¨è¿è¡Œæ—¶é€šè¿‡ `CapabilityDescriptor` æš´éœ²å„ Provider çš„èƒ½åŠ›å·®å¼‚ï¼Œç”±ä¸Šå±‚ä¸šåŠ¡å†³å®šæ˜¯å¦ç¦ç”¨æˆ–å¼€å¯ç‰¹å®šåŠŸèƒ½ã€‚

| Provider | Streaming | Image Input | Audio Input | Video Input | Tool Use | Structured Output |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **OpenAI Chat** | âœ… | âœ… | âœ… | âš ï¸ | âœ… | âœ… |
| **OpenAI Responses** | âœ… | âœ… | âš ï¸ | âš ï¸ | âœ… | âœ… |
| **Anthropic Messages** | âœ… | âœ… (base64) | âŒ | âŒ | âœ… | âš ï¸ |
| **Google Gemini** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |

> **æ³¨**ï¼š`CapabilityDescriptor` ä¸­æ ‡è®°ä¸º `false` çš„èƒ½åŠ›å¹¶ä¸æ„å‘³ç€ API ç»å¯¹ä¸æ”¯æŒï¼Œè€Œæ˜¯å½“å‰ Crate å°šæœªå°è£…æˆ–å‚å•†ä»…æä¾›å—é™æ”¯æŒã€‚

## å¼€å‘ä¸è´¡çŒ®

æ¬¢è¿ç¤¾åŒºè´¡çŒ®æ–°çš„ Provider å®ç°æˆ–æ”¹è¿›ç°æœ‰åŠŸèƒ½ã€‚

### ç¯å¢ƒè®¾ç½®
```bash
# æ ¼å¼åŒ–ä»£ç 
cargo fmt

# é™æ€æ£€æŸ¥
cargo clippy

# è¿è¡Œå•å…ƒæµ‹è¯• (Request/Response æ˜ å°„é€»è¾‘)
cargo test --lib

# è¿è¡Œé›†æˆæµ‹è¯•
cargo test --test integration -- --ignored
```

### æ–‡æ¡£
è¯¦ç»†çš„æ¶æ„è¯´æ˜ä¸ Provider æŒ‡å—è¯·å‚é˜… `docs/` ç›®å½•ä¸‹çš„ mdBook æ–‡æ¡£ã€‚
```bash
mdbook serve docs --open
```

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
